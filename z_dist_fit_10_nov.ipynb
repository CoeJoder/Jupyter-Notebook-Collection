{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import xlrd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')  # standard rendering tool for matplotlib above\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "import scipy.stats as st\n",
    "from matplotlib import rcParams\n",
    "\n",
    "\n",
    "# retrieve xlsx file, user inputs name of file\n",
    "location = raw_input(\"What is the name of your excel file?\")\n",
    "file_location = str(location) + \".xlsx\"\n",
    "workbook = xlrd.open_workbook(file_location)\n",
    "sheet = workbook.sheet_by_index(0)\n",
    "\n",
    "# Determine peak threshold\n",
    "user_threshold = float(raw_input(\"Enter % for threshold (1-100)\"))\n",
    "# create blank lists to store excel columns\n",
    "time = []\n",
    "data = []\n",
    "\n",
    "# retrieve time (col A) and data (col B)\n",
    "for row in range(sheet.nrows):\n",
    "    time.append(sheet.cell_value(row, 0))\n",
    "    data.append(sheet.cell_value(row, 1))\n",
    "\n",
    "# convert the lists to NumPy arrays, which are much faster, and can be\n",
    "# passed as parameters to NumPy/SciPy matrix functions\n",
    "\n",
    "actual_time = time\n",
    "actual_data = data\n",
    "\n",
    "\n",
    "# call z to cumulative proportion and vice versa\n",
    "# input st.norm.ppf(.95)\n",
    "# return 1.6448536269514722\n",
    "# input st.norm.cdf(1.64)\n",
    "# return 0.94949741652589625\n",
    "# normal function: ((1 / (np.sqrt(2 * np.pi * 1 ** 2))) * (np.e ** ((-1) * (((0 - 0) ** 2) / (2 * 1 ** 2)))))\n",
    "# sample dataset = home1\n",
    "# convert to total a6mt metabolite (data are in ng/h; desire ng\n",
    "\n",
    "def normal(x, mu, sigma):\n",
    "    normal_ht = (1 / (np.sqrt(2 * np.pi * sigma ** 2))) * (np.e ** ((-1) * (((x - mu) ** 2) / (2 * sigma ** 2))))\n",
    "    return normal_ht\n",
    "\n",
    "\n",
    "def std_normal(x):\n",
    "    std_normal_ht = (1 / (np.sqrt(2 * np.pi * 1 ** 2))) * (np.e ** ((-1) * (((x - 0) ** 2) / (2 * 1 ** 2))))\n",
    "    return std_normal_ht\n",
    "\n",
    "\n",
    "total_ng_list = []\n",
    "\n",
    "# function serving to convert ng per interval to total cumulative ng\n",
    "def total_ng(time, data):\n",
    "    total_sum = 0\n",
    "    total_ng_list.append(0)\n",
    "    for i in range(len(time)-1):\n",
    "        mp_sum = (time[i+1] - time[i])*data[i + 1]\n",
    "        total_sum += mp_sum\n",
    "        total_ng_list.append(total_sum)\n",
    "    return total_sum\n",
    "\n",
    "\n",
    "total = total_ng(time, data)\n",
    "\n",
    "# convert cumulative ng produced to proportion of total\n",
    "prop_list = []\n",
    "\n",
    "\n",
    "def find_totals(x):\n",
    "    for totals in x:\n",
    "        props = totals / total\n",
    "        prop_list.append(props)\n",
    "    return prop_list\n",
    "\n",
    "\n",
    "actual_cumulative_proportions = find_totals(total_ng_list)\n",
    "\n",
    "\n",
    "# input cumulative proportion list, convert to z score list\n",
    "z_list = []\n",
    "\n",
    "\n",
    "def get_z(x):\n",
    "    for prop in x:\n",
    "        z = st.norm.ppf(prop)\n",
    "        z_list.append(z)\n",
    "    return z_list\n",
    "\n",
    "\n",
    "actual_z_scores = get_z(prop_list)\n",
    "\n",
    "\n",
    "# find y values for each z score in actual z scores list\n",
    "actual_z_ht = []\n",
    "\n",
    "\n",
    "for z in actual_z_scores:\n",
    "    ht = ((1 / (np.sqrt(2 * np.pi * 1 ** 2))) * (np.e ** ((-1) * (((z - 0) ** 2) / (2 * 1 ** 2)))))\n",
    "    actual_z_ht.append(ht)\n",
    "\n",
    "\n",
    "# determine values: time (hr) and z, occurring directly prior and directly after, the 50% ng total\n",
    "# solve for linear (actual point to actual point) 50% total time aka acrophase\n",
    "linear_acrophase = 0\n",
    "pre_mid_z = 0\n",
    "pre_mid_time = 0\n",
    "post_mid_z = 0\n",
    "post_mid_time = 0\n",
    "prop_step = 0\n",
    "\n",
    "while prop_step < len(total_ng_list):\n",
    "    if total_ng_list[prop_step] < total/2:\n",
    "        if total_ng_list[prop_step+1] > total/2:\n",
    "            linear_acrophase = (0.5*total-(total_ng_list[prop_step+1]-((total_ng_list[prop_step+1]-total_ng_list[prop_step])/\n",
    "                                                                  (time[prop_step+1]-time[prop_step]))*time[prop_step+1]))/((total_ng_list[prop_step+1]-total_ng_list[prop_step])/(time[prop_step+1]-time[prop_step]))\n",
    "            pre_mid_time = time[prop_step]\n",
    "            post_mid_time = time[prop_step+1]\n",
    "            pre_mid_z = z_list[prop_step]\n",
    "            post_mid_z = z_list[prop_step+1]\n",
    "            break\n",
    "    prop_step += 1\n",
    "\n",
    "# ignoring linearly determined acrophase, algebraically solve for sigma, then mu, of a normal distribution using only\n",
    "# time, z scores of datapoints directly preceding and proceeding the 50% ng total\n",
    "normal_sigma = (post_mid_time - pre_mid_time) / (post_mid_z - pre_mid_z)\n",
    "normal_acrophase = post_mid_time - post_mid_z * normal_sigma\n",
    "normal_acrophase_ht = normal(normal_acrophase, normal_acrophase, normal_sigma)\n",
    "fitted_acrophase_ht = normal_acrophase_ht*total\n",
    "# saving this normal distribution formula for future use; pay no attention!\n",
    "#(((1 / (np.sqrt(2 * np.pi * 1 ** 2))) * (np.e ** ((-1) * (((0 - 0) ** 2) / (2 * 1 ** 2)))))/((1 / (np.sqrt(2 * np.pi * 1 ** 2))) * (np.e ** ((-1) * (((pre_mid_z - 0) ** 2) / (2 * 1 ** 2))))))\n",
    "\n",
    "# given computed mu and sigma of fitted normal distribution, fit z scores onto actual data\n",
    "fit_z = []\n",
    "for hr in actual_time:\n",
    "    fitted_z = (hr - normal_acrophase)/normal_sigma\n",
    "    fit_z.append(fitted_z)\n",
    "\n",
    "# given computed mu and sigma of fitted normal distribution, fit y values onto actual data\n",
    "fit_ht = []\n",
    "for z in actual_time:\n",
    "    ht = normal(z, normal_acrophase, normal_sigma)\n",
    "    fit_ht.append(ht)\n",
    "\n",
    "# given computed mu and sigma of fitted normal distribution, fit cumulative proportions onto actual data\n",
    "fit_cdf = []\n",
    "for z in fit_z:\n",
    "    cdf = st.norm.cdf(z)\n",
    "    fit_cdf.append(cdf)\n",
    "\n",
    "# given computed mu and sigma of fitted normal distribution, fit real y values (total ng * z ht) to actual data\n",
    "fit_ng = []\n",
    "for ht in fit_ht:\n",
    "    ngs = total*ht\n",
    "    fit_ng.append(ngs)\n",
    "\n",
    "# determine threshold for onset and offset\n",
    "fitted_midpoint = fitted_acrophase_ht*(user_threshold/100)\n",
    "\n",
    "# list below is for figure display purposes only\n",
    "fitted_midpoint_list = []\n",
    "for items in time:\n",
    "    fitted_midpoint_list.append(fitted_midpoint)\n",
    "\n",
    "# prepare actual time and data to estimate ng/h values in order to compare to actual values, to generate SSresiduals\n",
    "time_fit = time\n",
    "data_fit = data\n",
    "data_fit_ng_h = []\n",
    "\n",
    "cum_step = 1\n",
    "data_fit_ng_h.append(0)\n",
    "while cum_step < len(data):\n",
    "    ngh = total*(fit_cdf[cum_step]-fit_cdf[cum_step-1])/(time[cum_step]-time[cum_step-1])\n",
    "    data_fit_ng_h.append(ngh)\n",
    "    cum_step += 1\n",
    "\n",
    "data_fit_ng_h = np.array(data_fit_ng_h)\n",
    "\n",
    "# mesor-data intersection points\n",
    "time = np.array(time)\n",
    "data = np.array(data)\n",
    "\n",
    "# below returns data index points prior to mesor crossing, writes these index values to y_int\n",
    "idx = np.argwhere(np.diff(np.sign(fitted_midpoint - data))).flatten()\n",
    "x_int = time[idx]\n",
    "y_int = []\n",
    "for coords in x_int:\n",
    "    y_int.append(fitted_midpoint)\n",
    "\n",
    "crossing_points = []\n",
    "\n",
    "# finds time values where mesor intersects with data (assuming straight line from point to point) \\\n",
    "# by generating straight line y = mx+b from two known points at each interval, and inverse to solve for y w/known time\n",
    "# writes each of these intersection timepoints to crossing_points list (y value is always mesor, this list is x \"time\")\n",
    "for intersect in idx:\n",
    "    crossing_points.append((fitted_midpoint-((data[intersect])-((data[intersect+1] - data[intersect])/(time[intersect+1] -\n",
    "                                                                                                 time[intersect])) *\n",
    "                                       time[intersect]))/((data[intersect+1] - data[intersect])/(time[intersect+1] -\n",
    "                                                                                                 time[intersect])))\n",
    "\n",
    "crossing_points = np.array(crossing_points)\n",
    "crossing_points_unstring = \", \".join(\"{0:.3f}\".format(num) for num in crossing_points)\n",
    "\n",
    "def pearson(x, y):\n",
    "    # computes pearson correlation coefficient (r) and coefficient of determination (r^2) between arrays x and y.\n",
    "    # also computes means (xmean, ymean), sums of squares (SSx, SSy) standard deviations (SDy, SDy), /\n",
    "    # covariance (COVxy) and degrees of freedom (rdf).\n",
    "\n",
    "    xlen = len(x)\n",
    "    ylen = len(y)\n",
    "\n",
    "    xsum = float(0)\n",
    "    ysum = float(0)\n",
    "\n",
    "    for values in x:\n",
    "        xsum += float(values)\n",
    "    for values in y:\n",
    "        ysum += float(values)\n",
    "\n",
    "    xmean = float(xsum/xlen)\n",
    "    ymean = float(ysum/ylen)\n",
    "    ss_x = float(0)\n",
    "    ss_y = float(0)\n",
    "\n",
    "    for values in x:\n",
    "        ss_x += float((values-xmean)**2)\n",
    "    for values in y:\n",
    "        ss_y += float((values-ymean)**2)\n",
    "\n",
    "    sd_x = float(ss_x/xlen)**.5\n",
    "    sd_y = float(ss_y/ylen)**.5\n",
    "\n",
    "    cov_xy = 0\n",
    "    rdf = len(x) - 2\n",
    "\n",
    "    for a, b in zip(x, y):\n",
    "        cov_xy += float((a-xmean)*(b-ymean))\n",
    "    # convert this to str containing dfs?\n",
    "    return float((cov_xy/xlen)/(sd_x*sd_y))\n",
    "\n",
    "\n",
    "correlation = pearson(data[1:], data_fit_ng_h[1:])\n",
    "r_squared = correlation**2\n",
    "\n",
    "ss = 0\n",
    "ss_step = 1\n",
    "while ss_step < len(data):\n",
    "    ss += (data[ss_step]-data_fit_ng_h[ss_step])**2\n",
    "    ss_step += 1\n",
    "\n",
    "# tuple pairing time and data values (line 168 of ski_slope_least_squares_1_oct\n",
    "time_data_tuple = zip(time, data)\n",
    "\n",
    "# combine time,data coords with crossing_points, lsq_mesor list, then arrange by time\n",
    "crossing_coords = sorted((zip(crossing_points, fitted_midpoint_list)) + time_data_tuple)\n",
    "sorted_coords = zip(*crossing_coords)\n",
    "# all_time is every original timepoint plus mesor intersection timepoints\n",
    "all_time = sorted_coords[0]\n",
    "# all_data is every original datapoint plus mesor value when mesor intersects data\n",
    "all_data = sorted_coords[1]\n",
    "\n",
    "# find position in sorted coords where crossing points appear (start and end of each auc computation)\n",
    "\n",
    "index_coords = []\n",
    "\n",
    "for pts in crossing_points:\n",
    "    for items in all_time:\n",
    "        if items == pts:\n",
    "            index_coords.append(all_time.index(items))\n",
    "\n",
    "# introduce lists that will be written as a function of whether curve is going up during mesor crossing (onset) \\\n",
    "# or down during crossing (offset) These are onset_coords and offset_coords, respectively.\n",
    "# onset and offset index_coords display the index number of these locations relative to position in all_time\n",
    "onset_coords = []\n",
    "onset_index_coords = []\n",
    "offset_coords = []\n",
    "offset_index_coords = []\n",
    "peak_data_list = []\n",
    "peak_time_list = []\n",
    "\n",
    "for pts in index_coords[0:(len(index_coords)-1)]:\n",
    "    if all_data[pts+1] > all_data[pts]:\n",
    "        onset_coords.append(pts)\n",
    "        onset_index_coords.append(index_coords.index(pts))\n",
    "\n",
    "for pts in index_coords[1:len(index_coords)]:\n",
    "    if all_data[pts+1] < all_data[pts]:\n",
    "        offset_coords.append(pts)\n",
    "        offset_index_coords.append(index_coords.index(pts))\n",
    "\n",
    "\n",
    "# filters all_time, and all_data arrays into arrays of lists, each sub-list beginning at onset, ending at offset\n",
    "# all other coordinates ignored\n",
    "# time list written to peak_time_list, data written to peak_data_list\n",
    "\n",
    "step = 0\n",
    "while step < (len(index_coords)):\n",
    "    if len(index_coords) <= 1:\n",
    "        print \"only 1 mesor crossing; cannot compute peak duration\"\n",
    "        step = len(index_coords)\n",
    "    elif index_coords[0] == onset_coords[0] and len(index_coords) % 2 == 0 and len(index_coords) >= 2:\n",
    "        peak_data_list.append(all_data[index_coords[step]:index_coords[step + 1]+1])\n",
    "        peak_time_list.append(all_time[index_coords[step]:index_coords[step + 1]+1])\n",
    "        step += 2\n",
    "    elif index_coords[0] == onset_coords[0] and len(index_coords) % 2 != 0 and len(index_coords) >= 3:\n",
    "        index_coords.pop()\n",
    "        peak_data_list.append(all_data[index_coords[step]:index_coords[step + 1] + 1])\n",
    "        peak_time_list.append(all_time[index_coords[step]:index_coords[step + 1] + 1])\n",
    "        step += 2\n",
    "    elif index_coords[0] != onset_coords[0] and len(index_coords) % 2 == 0 and len(index_coords) >= 3:\n",
    "        index_coords = index_coords[1:-1]\n",
    "    elif index_coords[0] != onset_coords[0] and len(index_coords) % 2 != 0 and len(index_coords) >= 3:\n",
    "        index_coords = index_coords[1:]\n",
    "    elif index_coords[0] != onset_coords[0] and len(index_coords) % 2 == 0 and len(index_coords) <= 2:\n",
    "        print \"not enough coordinates to determine\"\n",
    "    else:\n",
    "        print \"on-off coordinates not found\"\n",
    "        step = len(index_coords)\n",
    "\n",
    "\n",
    "# midpoint auc calculation\n",
    "def midpoint_peak_auc(time, data):\n",
    "    total_sum = 0\n",
    "    for i in range(len(time)-1):\n",
    "        mp_sum = (time[i+1] - time[i])*((data[i] + data[i + 1])/2)\n",
    "        total_sum += mp_sum\n",
    "    return total_sum\n",
    "\n",
    "\n",
    "# write all peak_mp_auc calculations to a list\n",
    "mp_cycle = 0\n",
    "peak_mp_auc_list = []\n",
    "\n",
    "while mp_cycle < len(peak_time_list):\n",
    "    peak_mp_auc_list.append(midpoint_peak_auc(peak_time_list[mp_cycle], peak_data_list[mp_cycle]))\n",
    "    mp_cycle += 1\n",
    "\n",
    "# determine actual data determined onset, offset, and peak duration; transform threshold cross times to printable format\n",
    "peak_duration = crossing_points[1] - crossing_points[0]\n",
    "peak_duration_unstring = float(peak_duration)\n",
    "peak_mp_auc_list_unstring = \", \".join(\"{0:.3f}\".format(num) for num in peak_mp_auc_list)\n",
    "onset = crossing_points[0]\n",
    "offset = crossing_points[1]\n",
    "\n",
    "\n",
    "# Find threshold crossings of normal distribution and corresponding z score\n",
    "fitted_offset = np.sqrt((2 * normal_sigma**2)*(-1*np.log((fitted_midpoint*np.sqrt(2*np.pi*normal_sigma**2))/total))) + normal_acrophase\n",
    "fitted_onset = (normal_acrophase - fitted_offset) + normal_acrophase\n",
    "fitted_duration = fitted_offset - fitted_onset\n",
    "threshold_z = (fitted_offset - normal_acrophase)/normal_sigma\n",
    "\n",
    "# setup the figure plots to be generated\n",
    "rcParams[\"figure.figsize\"] = (10, 14)\n",
    "rcParams[\"legend.fontsize\"] = 16\n",
    "rcParams[\"axes.labelsize\"] = 16\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "# create a blank figure\n",
    "fig = plt.figure()\n",
    "\n",
    "# add a plot (2x1 grid in the 1st position)\n",
    "axes = fig.add_subplot(211)\n",
    "\n",
    "# generate smooth fitted curves by upping the resolution to 100\n",
    "time_fit = np.linspace(time.min(), time.max(), 100)\n",
    "data_fit = total*(normal(time_fit, normal_acrophase, normal_sigma))\n",
    "acro_x_y = (normal_acrophase, fitted_acrophase_ht)\n",
    "# plot the data (\"ro\" = red circles) and the fit (\"r-\" = red line)\n",
    "axes.plot(time, data, \"k-\")\n",
    "axes.plot(time, data, \"ko\", label=\"Actual Data\")\n",
    "axes.plot(time_fit, data_fit, \"r-\", label=\"ng Fit\")\n",
    "axes.plot(time, data_fit_ng_h, \"g-\", label=\"ng/h Fit\")\n",
    "axes.plot(normal_acrophase, fitted_acrophase_ht, \"ro\")\n",
    "plt.hlines(fitted_midpoint_list, time[0], time[len(time)-1], \"y\", label=\"Peak Threshold\")\n",
    "axes.plot(crossing_points, y_int, \"yo\")\n",
    "axes.plot(fitted_onset, fitted_midpoint, \"yo\")\n",
    "axes.plot(fitted_offset, fitted_midpoint, \"yo\")\n",
    "\n",
    "# add a legend\n",
    "axes.set_title(\"Z Distribution Fit\")\n",
    "axes.set_xlabel(\"Hour\")\n",
    "axes.set_ylabel(\"aMT6\")\n",
    "axes.legend()\n",
    "\n",
    "# add a text box below the graph\n",
    "axes2 = fig.add_subplot(212)\n",
    "axes2.axis(\"off\")\n",
    "\n",
    "# create function with properly formatted output underneath figure\n",
    "def append_text(x_pos, y_pos, ss, num_residuals, r, r2, acro_x, acro_y, mesor, peak_duration_unstring, cross_time, auc, color, mu, sigma, total, onset, offset, threshold, fit_on, fit_off, fit_duration, fit_z):\n",
    "    \"\"\"Appends the residual data below the chart\n",
    "    x_pos         -- x-position\n",
    "    y_pos         -- y-position\n",
    "    num_residuals -- number of residuals\n",
    "    r             -- sum of residuals\n",
    "    r2            -- sum of squared residuals\n",
    "    \"\"\"\n",
    "    strfmt = \"h = {1:.4f}, b = {2:.4f}, v = {3:.4f}, p = {4:.4f}\"\n",
    "    axes2.text(x_pos, y_pos,\n",
    "            # surrounding text in $-symbols will format it as math equations\n",
    "            \"$r({1:d}) = {2:,.3f}$,  $r^2({1:d}) = {3:,.3f}$, Sum of Squares (SS) = {0:,.3f}\\n\\nmu = {10:.3f} h\\nsigma = {11:.3f} h\\n\\nTotal aMT6 = {12:.3f} ng\\n\\nPeak Coordinates = ({4:,.3f}, {5:,.3f})\\n\\nAcrophase = {4:,.3f} h, Max Value = {5:,.3f} ng\\n\\n{15:,.1f}% Threshold = {6:,.3f} ng\\n\\nOnset = {13:,.3f} h\\nOffset = {14:,.3f} h \\nPeak Duration = {7:,.3f} h\\n\\nFitted Onset = {16:.3f} h\\nFitted Offset = {17:.3f} h\\nFitted Duration = {18:.3f} h\\nFitted Z Threshold = +/-{19:.3f}\".format\n",
    "               (ss, num_residuals - 3, r, r2, acro_x, acro_y, mesor, peak_duration_unstring, cross_time, auc, mu, sigma, total, onset, offset, threshold, fit_on, fit_off, fit_duration, fit_z),\n",
    "            color=color,\n",
    "            fontsize=16,\n",
    "            horizontalalignment=\"left\",\n",
    "            verticalalignment=\"top\",\n",
    "            wrap=True,\n",
    "            transform=axes2.transAxes)\n",
    "\n",
    "\n",
    "# insert residual info along the left side of text box\n",
    "append_text(.02, .96, ss, len(data), correlation, r_squared, normal_acrophase, fitted_acrophase_ht, fitted_midpoint,\n",
    "           peak_duration_unstring, crossing_points_unstring, peak_mp_auc_list_unstring, \"k\", normal_acrophase, normal_sigma, total, onset, offset, user_threshold, fitted_onset, fitted_offset, fitted_duration, threshold_z),\n",
    "\n",
    "\n",
    "# save the figure as an image file in the current directory\n",
    "# fig.savefig(os.path.join(os.getcwd(), str(location)+\"_z_dist_output.png\"))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print \"Original (time, aMT6 ng/h) coordinates:\"\n",
    "print zip(time, data)\n",
    "print \"Total ng secreted = %.3f ng\" % total\n",
    "print \"pre mid time: %s, pre mid z: %.3f, post mid time: %s, post mid z: %.3f\" % (pre_mid_time, pre_mid_z, post_mid_time, post_mid_z)\n",
    "print \"Actual Z-scores: %s\" % actual_z_scores\n",
    "print \"Actual cumulative proportions: %s\" % actual_cumulative_proportions\n",
    "print \"Actual Standard Normal Ht: %s\" % actual_z_ht\n",
    "print \"Linear Acrophase: %.3f\" % linear_acrophase\n",
    "print \"Normal Distribution Mu = %.3f, sigma = %.3f\" % (normal_acrophase, normal_sigma)\n",
    "print \"Normal Acrophase ht: %.3f\" % normal_acrophase_ht\n",
    "print \"Fitted Acrophase ht: %.3f\" % fitted_acrophase_ht\n",
    "print \"Fitted Z: %s\" % fit_z\n",
    "print \"Fitted cumulative proportions: %s\" % fit_cdf\n",
    "print \"Fitted ht: %s\" % fit_ht\n",
    "print \"Fitted ng = %s\" % fit_ng\n",
    "print \"SS = %.3f\" % ss\n",
    "print \"Fitted ng/h = %s\" % data_fit_ng_h\n",
    "print fitted_onset\n",
    "print fitted_offset\n",
    "print \"Threshold z = +/-%.3f\" % threshold_z\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
