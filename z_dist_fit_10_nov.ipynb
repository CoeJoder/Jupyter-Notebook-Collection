{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import sys\n",
    "import xlrd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "import scipy.stats as st\n",
    "from matplotlib import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What is the name of your excel file? test\n",
      "Enter % for threshold (1-100) 50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b7a070610f14267a5de252409f52a6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original (time, aMT6 ng/h) coordinates:\n",
      "[(20.483333333333334, 0.0), (21.841666666666665, 0.0), (22.933333333333337, 0.0), (23.76666666666667, 858.7305874000002), (25.0, 1195.0684098666666), (26.433333333333337, 1564.2036729000001), (27.858333333333334, 2118.0855637333334), (29.45, 1135.5309888), (31.06666666666667, 456.2400732631578), (32.458333333333336, 596.0531262400001), (33.84166666666667, 661.2397960000001), (35.35833333333333, 0.0), (36.85, 0.0), (38.35, 0.0), (39.9, 0.0), (41.391666666666666, 0.0), (42.86666666666666, 0.0)]\n",
      "Total ng secreted = 11739.021 ng\n",
      "pre mid time: 26.4333333333, pre mid z: -0.312, post mid time: 27.8583333333, post mid z: 0.344\n",
      "Actual Z-scores: [-inf, -inf, -inf, -1.5467660192982544, -0.8908047552252757, -0.31203732162762493, 0.3441161480044925, 0.8015195933969533, 1.0425288151662546, 1.4191962975968546, inf, inf, inf, inf, inf, inf, inf]\n",
      "Actual cumulative proportions: [0.0, 0.0, 0.0, 0.06095983846830116, 0.18651696182410227, 0.3775060799068353, 0.6346205303342405, 0.7885845471483303, 0.8514167134404458, 0.9220791024615431, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Actual Standard Normal Ht: [0.0, 0.0, 0.0, 0.12061144575523876, 0.2682850916217437, 0.3799855025214051, 0.3760073849865687, 0.28933926197457815, 0.23168613296449972, 0.14573030394581477, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Linear Acrophase: 27.112\n",
      "Normal Distribution Mu = 27.111, sigma = 2.172\n",
      "Normal Acrophase ht: 0.184\n",
      "Fitted Acrophase ht: 2156.416\n",
      "Fitted Z: [-3.05176584395121, -2.4263096126644546, -1.9236423347591447, -1.5399268554421168, -0.9720279460529158, -0.312037321627625, 0.3441161480044924, 1.077012713500016, 1.8214207433750533, 2.4622255938344906, 3.0991932895007577, 3.797555461857746, 4.48440616983523, 5.175094032605881, 5.888804824135553, 6.575655532113035, 7.254831930504173]\n",
      "Fitted cumulative proportions: [0.0011374974730864694, 0.007626625592051121, 0.027199715357142593, 0.061789091892471296, 0.16551832295753227, 0.37750607990683527, 0.6346205303342405, 0.859262707013135, 0.9657285378264749, 0.99309611067254, 0.9990297581118085, 0.9999269349563545, 0.9999963441364486, 0.9999998861018874, 0.9999999980550074, 0.9999999999757804, 0.9999999999997989]\n",
      "Fitted ht: [0.0017448122890332289, 0.009677418617828183, 0.02887812667880646, 0.056125878708236904, 0.11453325280169352, 0.17496758308022747, 0.17313582474823644, 0.10285355390409301, 0.03497024650417201, 0.008864077957410411, 0.0015080008593163074, 0.00013568362626782346, 7.893899872985933e-06, 2.808991749880352e-07, 5.418309095896772e-09, 7.495795532741048e-11, 6.840372042107731e-13]\n",
      "Fitted ng = [20.482388070458377, 113.60342020542753, 339.00093500081175, 658.8628677842216, 1344.5082577656722, 2053.948128933161, 2032.4450794401268, 1207.4000273443294, 410.51645745509796, 104.05559712734143, 17.702453728254937, 1.592792935659839, 0.09266665623809162, 0.0032974813089862187, 6.360564416321497e-05, 8.799330103496681e-07, 8.029927092638453e-09]\n",
      "SS = 1136893.436\n",
      "Fitted ng/h = [0.00000000e+00 5.60804990e+01 2.10475339e+02 4.87254500e+02\n",
      " 9.87307800e+02 1.73618283e+03 2.11808556e+03 1.65680370e+03\n",
      " 7.73075024e+02 2.30851625e+02 5.03531651e+01 6.94416119e+00\n",
      " 5.46231836e-01 2.77194711e-02 8.47883887e-04 1.51159739e-05\n",
      " 1.91155551e-07]\n",
      "24.553961881626208\n",
      "29.66803765729874\n",
      "Threshold z = +/-1.177\n"
     ]
    }
   ],
   "source": [
    "# retrieve xlsx file, user inputs name of file\n",
    "location = raw_input(\"What is the name of your excel file?\")\n",
    "file_location = str(location) + \".xlsx\"\n",
    "workbook = xlrd.open_workbook(file_location)\n",
    "sheet = workbook.sheet_by_index(0)\n",
    "\n",
    "# Determine peak threshold\n",
    "user_threshold = float(raw_input(\"Enter % for threshold (1-100)\"))\n",
    "# create blank lists to store excel columns\n",
    "time = []\n",
    "data = []\n",
    "\n",
    "# retrieve time (col A) and data (col B)\n",
    "for row in range(sheet.nrows):\n",
    "    time.append(sheet.cell_value(row, 0))\n",
    "    data.append(sheet.cell_value(row, 1))\n",
    "\n",
    "# convert the lists to NumPy arrays, which are much faster, and can be\n",
    "# passed as parameters to NumPy/SciPy matrix functions\n",
    "\n",
    "actual_time = time\n",
    "actual_data = data\n",
    "\n",
    "\n",
    "# call z to cumulative proportion and vice versa\n",
    "# input st.norm.ppf(.95)\n",
    "# return 1.6448536269514722\n",
    "# input st.norm.cdf(1.64)\n",
    "# return 0.94949741652589625\n",
    "# normal function: ((1 / (np.sqrt(2 * np.pi * 1 ** 2))) * (np.e ** ((-1) * (((0 - 0) ** 2) / (2 * 1 ** 2)))))\n",
    "# sample dataset = home1\n",
    "# convert to total a6mt metabolite (data are in ng/h; desire ng\n",
    "\n",
    "def normal(x, mu, sigma):\n",
    "    normal_ht = (1 / (np.sqrt(2 * np.pi * sigma ** 2))) * (np.e ** ((-1) * (((x - mu) ** 2) / (2 * sigma ** 2))))\n",
    "    return normal_ht\n",
    "\n",
    "\n",
    "def std_normal(x):\n",
    "    std_normal_ht = (1 / (np.sqrt(2 * np.pi * 1 ** 2))) * (np.e ** ((-1) * (((x - 0) ** 2) / (2 * 1 ** 2))))\n",
    "    return std_normal_ht\n",
    "\n",
    "\n",
    "total_ng_list = []\n",
    "\n",
    "# function serving to convert ng per interval to total cumulative ng\n",
    "def total_ng(time, data):\n",
    "    total_sum = 0\n",
    "    total_ng_list.append(0)\n",
    "    for i in range(len(time)-1):\n",
    "        mp_sum = (time[i+1] - time[i])*data[i + 1]\n",
    "        total_sum += mp_sum\n",
    "        total_ng_list.append(total_sum)\n",
    "    return total_sum\n",
    "\n",
    "\n",
    "total = total_ng(time, data)\n",
    "\n",
    "# convert cumulative ng produced to proportion of total\n",
    "prop_list = []\n",
    "\n",
    "\n",
    "def find_totals(x):\n",
    "    for totals in x:\n",
    "        props = totals / total\n",
    "        prop_list.append(props)\n",
    "    return prop_list\n",
    "\n",
    "\n",
    "actual_cumulative_proportions = find_totals(total_ng_list)\n",
    "\n",
    "\n",
    "# input cumulative proportion list, convert to z score list\n",
    "z_list = []\n",
    "\n",
    "\n",
    "def get_z(x):\n",
    "    for prop in x:\n",
    "        z = st.norm.ppf(prop)\n",
    "        z_list.append(z)\n",
    "    return z_list\n",
    "\n",
    "\n",
    "actual_z_scores = get_z(prop_list)\n",
    "\n",
    "\n",
    "# find y values for each z score in actual z scores list\n",
    "actual_z_ht = []\n",
    "\n",
    "\n",
    "for z in actual_z_scores:\n",
    "    ht = ((1 / (np.sqrt(2 * np.pi * 1 ** 2))) * (np.e ** ((-1) * (((z - 0) ** 2) / (2 * 1 ** 2)))))\n",
    "    actual_z_ht.append(ht)\n",
    "\n",
    "\n",
    "# determine values: time (hr) and z, occurring directly prior and directly after, the 50% ng total\n",
    "# solve for linear (actual point to actual point) 50% total time aka acrophase\n",
    "linear_acrophase = 0\n",
    "pre_mid_z = 0\n",
    "pre_mid_time = 0\n",
    "post_mid_z = 0\n",
    "post_mid_time = 0\n",
    "prop_step = 0\n",
    "\n",
    "while prop_step < len(total_ng_list):\n",
    "    if total_ng_list[prop_step] < total/2:\n",
    "        if total_ng_list[prop_step+1] > total/2:\n",
    "            linear_acrophase = (0.5*total-(total_ng_list[prop_step+1]-((total_ng_list[prop_step+1]-total_ng_list[prop_step])/\n",
    "                                                                  (time[prop_step+1]-time[prop_step]))*time[prop_step+1]))/((total_ng_list[prop_step+1]-total_ng_list[prop_step])/(time[prop_step+1]-time[prop_step]))\n",
    "            pre_mid_time = time[prop_step]\n",
    "            post_mid_time = time[prop_step+1]\n",
    "            pre_mid_z = z_list[prop_step]\n",
    "            post_mid_z = z_list[prop_step+1]\n",
    "            break\n",
    "    prop_step += 1\n",
    "\n",
    "# ignoring linearly determined acrophase, algebraically solve for sigma, then mu, of a normal distribution using only\n",
    "# time, z scores of datapoints directly preceding and proceeding the 50% ng total\n",
    "normal_sigma = (post_mid_time - pre_mid_time) / (post_mid_z - pre_mid_z)\n",
    "normal_acrophase = post_mid_time - post_mid_z * normal_sigma\n",
    "normal_acrophase_ht = normal(normal_acrophase, normal_acrophase, normal_sigma)\n",
    "fitted_acrophase_ht = normal_acrophase_ht*total\n",
    "# saving this normal distribution formula for future use; pay no attention!\n",
    "#(((1 / (np.sqrt(2 * np.pi * 1 ** 2))) * (np.e ** ((-1) * (((0 - 0) ** 2) / (2 * 1 ** 2)))))/((1 / (np.sqrt(2 * np.pi * 1 ** 2))) * (np.e ** ((-1) * (((pre_mid_z - 0) ** 2) / (2 * 1 ** 2))))))\n",
    "\n",
    "# given computed mu and sigma of fitted normal distribution, fit z scores onto actual data\n",
    "fit_z = []\n",
    "for hr in actual_time:\n",
    "    fitted_z = (hr - normal_acrophase)/normal_sigma\n",
    "    fit_z.append(fitted_z)\n",
    "\n",
    "# given computed mu and sigma of fitted normal distribution, fit y values onto actual data\n",
    "fit_ht = []\n",
    "for z in actual_time:\n",
    "    ht = normal(z, normal_acrophase, normal_sigma)\n",
    "    fit_ht.append(ht)\n",
    "\n",
    "# given computed mu and sigma of fitted normal distribution, fit cumulative proportions onto actual data\n",
    "fit_cdf = []\n",
    "for z in fit_z:\n",
    "    cdf = st.norm.cdf(z)\n",
    "    fit_cdf.append(cdf)\n",
    "\n",
    "# given computed mu and sigma of fitted normal distribution, fit real y values (total ng * z ht) to actual data\n",
    "fit_ng = []\n",
    "for ht in fit_ht:\n",
    "    ngs = total*ht\n",
    "    fit_ng.append(ngs)\n",
    "\n",
    "# determine threshold for onset and offset\n",
    "fitted_midpoint = fitted_acrophase_ht*(user_threshold/100)\n",
    "\n",
    "# list below is for figure display purposes only\n",
    "fitted_midpoint_list = []\n",
    "for items in time:\n",
    "    fitted_midpoint_list.append(fitted_midpoint)\n",
    "\n",
    "# prepare actual time and data to estimate ng/h values in order to compare to actual values, to generate SSresiduals\n",
    "time_fit = time\n",
    "data_fit = data\n",
    "data_fit_ng_h = []\n",
    "\n",
    "cum_step = 1\n",
    "data_fit_ng_h.append(0)\n",
    "while cum_step < len(data):\n",
    "    ngh = total*(fit_cdf[cum_step]-fit_cdf[cum_step-1])/(time[cum_step]-time[cum_step-1])\n",
    "    data_fit_ng_h.append(ngh)\n",
    "    cum_step += 1\n",
    "\n",
    "data_fit_ng_h = np.array(data_fit_ng_h)\n",
    "\n",
    "# mesor-data intersection points\n",
    "time = np.array(time)\n",
    "data = np.array(data)\n",
    "\n",
    "# below returns data index points prior to mesor crossing, writes these index values to y_int\n",
    "idx = np.argwhere(np.diff(np.sign(fitted_midpoint - data))).flatten()\n",
    "x_int = time[idx]\n",
    "y_int = []\n",
    "for coords in x_int:\n",
    "    y_int.append(fitted_midpoint)\n",
    "\n",
    "crossing_points = []\n",
    "\n",
    "# finds time values where mesor intersects with data (assuming straight line from point to point) \\\n",
    "# by generating straight line y = mx+b from two known points at each interval, and inverse to solve for y w/known time\n",
    "# writes each of these intersection timepoints to crossing_points list (y value is always mesor, this list is x \"time\")\n",
    "for intersect in idx:\n",
    "    crossing_points.append((fitted_midpoint-((data[intersect])-((data[intersect+1] - data[intersect])/(time[intersect+1] -\n",
    "                                                                                                 time[intersect])) *\n",
    "                                       time[intersect]))/((data[intersect+1] - data[intersect])/(time[intersect+1] -\n",
    "                                                                                                 time[intersect])))\n",
    "\n",
    "crossing_points = np.array(crossing_points)\n",
    "crossing_points_unstring = \", \".join(\"{0:.3f}\".format(num) for num in crossing_points)\n",
    "\n",
    "def pearson(x, y):\n",
    "    # computes pearson correlation coefficient (r) and coefficient of determination (r^2) between arrays x and y.\n",
    "    # also computes means (xmean, ymean), sums of squares (SSx, SSy) standard deviations (SDy, SDy), /\n",
    "    # covariance (COVxy) and degrees of freedom (rdf).\n",
    "\n",
    "    xlen = len(x)\n",
    "    ylen = len(y)\n",
    "\n",
    "    xsum = float(0)\n",
    "    ysum = float(0)\n",
    "\n",
    "    for values in x:\n",
    "        xsum += float(values)\n",
    "    for values in y:\n",
    "        ysum += float(values)\n",
    "\n",
    "    xmean = float(xsum/xlen)\n",
    "    ymean = float(ysum/ylen)\n",
    "    ss_x = float(0)\n",
    "    ss_y = float(0)\n",
    "\n",
    "    for values in x:\n",
    "        ss_x += float((values-xmean)**2)\n",
    "    for values in y:\n",
    "        ss_y += float((values-ymean)**2)\n",
    "\n",
    "    sd_x = float(ss_x/xlen)**.5\n",
    "    sd_y = float(ss_y/ylen)**.5\n",
    "\n",
    "    cov_xy = 0\n",
    "    rdf = len(x) - 2\n",
    "\n",
    "    for a, b in zip(x, y):\n",
    "        cov_xy += float((a-xmean)*(b-ymean))\n",
    "    # convert this to str containing dfs?\n",
    "    return float((cov_xy/xlen)/(sd_x*sd_y))\n",
    "\n",
    "\n",
    "correlation = pearson(data[1:], data_fit_ng_h[1:])\n",
    "r_squared = correlation**2\n",
    "\n",
    "ss = 0\n",
    "ss_step = 1\n",
    "while ss_step < len(data):\n",
    "    ss += (data[ss_step]-data_fit_ng_h[ss_step])**2\n",
    "    ss_step += 1\n",
    "\n",
    "# tuple pairing time and data values (line 168 of ski_slope_least_squares_1_oct\n",
    "time_data_tuple = zip(time, data)\n",
    "\n",
    "# combine time,data coords with crossing_points, lsq_mesor list, then arrange by time\n",
    "crossing_coords = sorted((zip(crossing_points, fitted_midpoint_list)) + time_data_tuple)\n",
    "sorted_coords = zip(*crossing_coords)\n",
    "# all_time is every original timepoint plus mesor intersection timepoints\n",
    "all_time = sorted_coords[0]\n",
    "# all_data is every original datapoint plus mesor value when mesor intersects data\n",
    "all_data = sorted_coords[1]\n",
    "\n",
    "# find position in sorted coords where crossing points appear (start and end of each auc computation)\n",
    "\n",
    "index_coords = []\n",
    "\n",
    "for pts in crossing_points:\n",
    "    for items in all_time:\n",
    "        if items == pts:\n",
    "            index_coords.append(all_time.index(items))\n",
    "\n",
    "# introduce lists that will be written as a function of whether curve is going up during mesor crossing (onset) \\\n",
    "# or down during crossing (offset) These are onset_coords and offset_coords, respectively.\n",
    "# onset and offset index_coords display the index number of these locations relative to position in all_time\n",
    "onset_coords = []\n",
    "onset_index_coords = []\n",
    "offset_coords = []\n",
    "offset_index_coords = []\n",
    "peak_data_list = []\n",
    "peak_time_list = []\n",
    "\n",
    "for pts in index_coords[0:(len(index_coords)-1)]:\n",
    "    if all_data[pts+1] > all_data[pts]:\n",
    "        onset_coords.append(pts)\n",
    "        onset_index_coords.append(index_coords.index(pts))\n",
    "\n",
    "for pts in index_coords[1:len(index_coords)]:\n",
    "    if all_data[pts+1] < all_data[pts]:\n",
    "        offset_coords.append(pts)\n",
    "        offset_index_coords.append(index_coords.index(pts))\n",
    "\n",
    "\n",
    "# filters all_time, and all_data arrays into arrays of lists, each sub-list beginning at onset, ending at offset\n",
    "# all other coordinates ignored\n",
    "# time list written to peak_time_list, data written to peak_data_list\n",
    "\n",
    "step = 0\n",
    "while step < (len(index_coords)):\n",
    "    if len(index_coords) <= 1:\n",
    "        print \"only 1 mesor crossing; cannot compute peak duration\"\n",
    "        step = len(index_coords)\n",
    "    elif index_coords[0] == onset_coords[0] and len(index_coords) % 2 == 0 and len(index_coords) >= 2:\n",
    "        peak_data_list.append(all_data[index_coords[step]:index_coords[step + 1]+1])\n",
    "        peak_time_list.append(all_time[index_coords[step]:index_coords[step + 1]+1])\n",
    "        step += 2\n",
    "    elif index_coords[0] == onset_coords[0] and len(index_coords) % 2 != 0 and len(index_coords) >= 3:\n",
    "        index_coords.pop()\n",
    "        peak_data_list.append(all_data[index_coords[step]:index_coords[step + 1] + 1])\n",
    "        peak_time_list.append(all_time[index_coords[step]:index_coords[step + 1] + 1])\n",
    "        step += 2\n",
    "    elif index_coords[0] != onset_coords[0] and len(index_coords) % 2 == 0 and len(index_coords) >= 3:\n",
    "        index_coords = index_coords[1:-1]\n",
    "    elif index_coords[0] != onset_coords[0] and len(index_coords) % 2 != 0 and len(index_coords) >= 3:\n",
    "        index_coords = index_coords[1:]\n",
    "    elif index_coords[0] != onset_coords[0] and len(index_coords) % 2 == 0 and len(index_coords) <= 2:\n",
    "        print \"not enough coordinates to determine\"\n",
    "    else:\n",
    "        print \"on-off coordinates not found\"\n",
    "        step = len(index_coords)\n",
    "\n",
    "\n",
    "# midpoint auc calculation\n",
    "def midpoint_peak_auc(time, data):\n",
    "    total_sum = 0\n",
    "    for i in range(len(time)-1):\n",
    "        mp_sum = (time[i+1] - time[i])*((data[i] + data[i + 1])/2)\n",
    "        total_sum += mp_sum\n",
    "    return total_sum\n",
    "\n",
    "\n",
    "# write all peak_mp_auc calculations to a list\n",
    "mp_cycle = 0\n",
    "peak_mp_auc_list = []\n",
    "\n",
    "while mp_cycle < len(peak_time_list):\n",
    "    peak_mp_auc_list.append(midpoint_peak_auc(peak_time_list[mp_cycle], peak_data_list[mp_cycle]))\n",
    "    mp_cycle += 1\n",
    "\n",
    "# determine actual data determined onset, offset, and peak duration; transform threshold cross times to printable format\n",
    "peak_duration = crossing_points[1] - crossing_points[0]\n",
    "peak_duration_unstring = float(peak_duration)\n",
    "peak_mp_auc_list_unstring = \", \".join(\"{0:.3f}\".format(num) for num in peak_mp_auc_list)\n",
    "onset = crossing_points[0]\n",
    "offset = crossing_points[1]\n",
    "\n",
    "\n",
    "# Find threshold crossings of normal distribution and corresponding z score\n",
    "fitted_offset = np.sqrt((2 * normal_sigma**2)*(-1*np.log((fitted_midpoint*np.sqrt(2*np.pi*normal_sigma**2))/total))) + normal_acrophase\n",
    "fitted_onset = (normal_acrophase - fitted_offset) + normal_acrophase\n",
    "fitted_duration = fitted_offset - fitted_onset\n",
    "threshold_z = (fitted_offset - normal_acrophase)/normal_sigma\n",
    "\n",
    "# setup the figure plots to be generated\n",
    "rcParams[\"figure.figsize\"] = (10, 14)\n",
    "rcParams[\"legend.fontsize\"] = 16\n",
    "rcParams[\"axes.labelsize\"] = 16\n",
    "\n",
    "# create a blank figure\n",
    "fig = plt.figure()\n",
    "\n",
    "# add a plot (2x1 grid in the 1st position)\n",
    "axes = fig.add_subplot(211)\n",
    "\n",
    "# generate smooth fitted curves by upping the resolution to 100\n",
    "time_fit = np.linspace(time.min(), time.max(), 100)\n",
    "data_fit = total*(normal(time_fit, normal_acrophase, normal_sigma))\n",
    "acro_x_y = (normal_acrophase, fitted_acrophase_ht)\n",
    "# plot the data (\"ro\" = red circles) and the fit (\"r-\" = red line)\n",
    "axes.plot(time, data, \"k-\")\n",
    "axes.plot(time, data, \"ko\", label=\"Actual Data\")\n",
    "axes.plot(time_fit, data_fit, \"r-\", label=\"ng Fit\")\n",
    "axes.plot(time, data_fit_ng_h, \"g-\", label=\"ng/h Fit\")\n",
    "axes.plot(normal_acrophase, fitted_acrophase_ht, \"ro\")\n",
    "plt.hlines(fitted_midpoint_list, time[0], time[len(time)-1], \"y\", label=\"Peak Threshold\")\n",
    "axes.plot(crossing_points, y_int, \"yo\")\n",
    "axes.plot(fitted_onset, fitted_midpoint, \"yo\")\n",
    "axes.plot(fitted_offset, fitted_midpoint, \"yo\")\n",
    "\n",
    "# add a legend\n",
    "axes.set_title(\"Z Distribution Fit\")\n",
    "axes.set_xlabel(\"Hour\")\n",
    "axes.set_ylabel(\"aMT6\")\n",
    "axes.legend()\n",
    "\n",
    "# add a text box below the graph\n",
    "axes2 = fig.add_subplot(212)\n",
    "axes2.axis(\"off\")\n",
    "\n",
    "# create function with properly formatted output underneath figure\n",
    "def append_text(x_pos, y_pos, ss, num_residuals, r, r2, acro_x, acro_y, mesor, peak_duration_unstring, cross_time, auc, color, mu, sigma, total, onset, offset, threshold, fit_on, fit_off, fit_duration, fit_z):\n",
    "    \"\"\"Appends the residual data below the chart\n",
    "    x_pos         -- x-position\n",
    "    y_pos         -- y-position\n",
    "    num_residuals -- number of residuals\n",
    "    r             -- sum of residuals\n",
    "    r2            -- sum of squared residuals\n",
    "    \"\"\"\n",
    "    strfmt = \"h = {1:.4f}, b = {2:.4f}, v = {3:.4f}, p = {4:.4f}\"\n",
    "    axes2.text(x_pos, y_pos,\n",
    "            # surrounding text in $-symbols will format it as math equations\n",
    "            \"$r({1:d}) = {2:,.3f}$,  $r^2({1:d}) = {3:,.3f}$, Sum of Squares (SS) = {0:,.3f}\\n\\nmu = {10:.3f} h\\nsigma = {11:.3f} h\\n\\nTotal aMT6 = {12:.3f} ng\\n\\nPeak Coordinates = ({4:,.3f}, {5:,.3f})\\n\\nAcrophase = {4:,.3f} h, Max Value = {5:,.3f} ng\\n\\n{15:,.1f}% Threshold = {6:,.3f} ng\\n\\nOnset = {13:,.3f} h\\nOffset = {14:,.3f} h \\nPeak Duration = {7:,.3f} h\\n\\nFitted Onset = {16:.3f} h\\nFitted Offset = {17:.3f} h\\nFitted Duration = {18:.3f} h\\nFitted Z Threshold = +/-{19:.3f}\".format\n",
    "               (ss, num_residuals - 3, r, r2, acro_x, acro_y, mesor, peak_duration_unstring, cross_time, auc, mu, sigma, total, onset, offset, threshold, fit_on, fit_off, fit_duration, fit_z),\n",
    "            color=color,\n",
    "            fontsize=16,\n",
    "            horizontalalignment=\"left\",\n",
    "            verticalalignment=\"top\",\n",
    "            wrap=True,\n",
    "            transform=axes2.transAxes)\n",
    "\n",
    "\n",
    "# insert residual info along the left side of text box\n",
    "append_text(.02, .96, ss, len(data), correlation, r_squared, normal_acrophase, fitted_acrophase_ht, fitted_midpoint,\n",
    "           peak_duration_unstring, crossing_points_unstring, peak_mp_auc_list_unstring, \"k\", normal_acrophase, normal_sigma, total, onset, offset, user_threshold, fitted_onset, fitted_offset, fitted_duration, threshold_z),\n",
    "\n",
    "\n",
    "# save the figure as an image file in the current directory\n",
    "# fig.savefig(os.path.join(os.getcwd(), str(location)+\"_z_dist_output.png\"))\n",
    "plt.plot()\n",
    "\n",
    "\n",
    "print \"Original (time, aMT6 ng/h) coordinates:\"\n",
    "print zip(time, data)\n",
    "print \"Total ng secreted = %.3f ng\" % total\n",
    "print \"pre mid time: %s, pre mid z: %.3f, post mid time: %s, post mid z: %.3f\" % (pre_mid_time, pre_mid_z, post_mid_time, post_mid_z)\n",
    "print \"Actual Z-scores: %s\" % actual_z_scores\n",
    "print \"Actual cumulative proportions: %s\" % actual_cumulative_proportions\n",
    "print \"Actual Standard Normal Ht: %s\" % actual_z_ht\n",
    "print \"Linear Acrophase: %.3f\" % linear_acrophase\n",
    "print \"Normal Distribution Mu = %.3f, sigma = %.3f\" % (normal_acrophase, normal_sigma)\n",
    "print \"Normal Acrophase ht: %.3f\" % normal_acrophase_ht\n",
    "print \"Fitted Acrophase ht: %.3f\" % fitted_acrophase_ht\n",
    "print \"Fitted Z: %s\" % fit_z\n",
    "print \"Fitted cumulative proportions: %s\" % fit_cdf\n",
    "print \"Fitted ht: %s\" % fit_ht\n",
    "print \"Fitted ng = %s\" % fit_ng\n",
    "print \"SS = %.3f\" % ss\n",
    "print \"Fitted ng/h = %s\" % data_fit_ng_h\n",
    "print fitted_onset\n",
    "print fitted_offset\n",
    "print \"Threshold z = +/-%.3f\" % threshold_z\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
